{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89e4078c",
   "metadata": {},
   "source": [
    "# Training Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5440b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig, PromptEncoderConfig, PrefixTuningConfig, IA3Config,\n",
    "    get_peft_model,\n",
    ")\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "    model_name_or_path = \"codellama/CodeLlama-7b-hf\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "    # model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"auto\",quantization_config={\"load_in_4bit\": True, \"bnb_4bit_compute_dtype\": torch.bfloat16})\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "    dataset = load_dataset(\"ntt2402vn/sm_2k8\", split=\"train\")\n",
    "    dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "    split_dataset = dataset.train_test_split(train_size=2896, test_size=576, seed=42)\n",
    "    train_dataset = split_dataset[\"train\"]\n",
    "    eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "    tokenizer.add_eos_token = True\n",
    "\n",
    "    if model_name_or_path == \"deepseek-ai/deepseek-coder-6.7b-base\" or model_name_or_path == \"deepseek-ai/deepseek-coder-6.7b-instruct\":\n",
    "        tokenizer.pad_token_id = 32018 \n",
    "    else:\n",
    "        tokenizer.pad_token_id = 0\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "    def tokenize(prompt, add_eos_token=True):\n",
    "        result = tokenizer(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            max_length=10031,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        if (\n",
    "                result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "                and len(result[\"input_ids\"]) < 10031\n",
    "                and add_eos_token\n",
    "            ):\n",
    "                result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "                result[\"attention_mask\"].append(1)\n",
    "\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def generate_prompt(data):\n",
    "        full_prompt =f\"\"\"You are an expert Solidity auditor specializing in smart contract security. Your task is to analyze Solidity smart contracts for vulnerabilities.\n",
    "\n",
    "        @@ Instruction:\n",
    "        Given a smart contract, identify all potential security risks:\n",
    "        {data[\"input\"]}\n",
    "\n",
    "        @@ Response:\n",
    "        {data[\"output\"]}\n",
    "    \"\"\"\n",
    "        full = tokenize(full_prompt)\n",
    "        question = tokenize(f\"\"\"You are an expert Solidity auditor specializing in smart contract security. Your task is to analyze Solidity smart contracts for vulnerabilities.\n",
    "\n",
    "        @@ Instruction:\n",
    "        Given a smart contract, identify all potential security risks:\n",
    "        {data[\"input\"]}\n",
    "\n",
    "        @@ Response:\n",
    "        \"\"\")\n",
    "\n",
    "        question_len = len(question['input_ids'])\n",
    "\n",
    "        full[\"labels\"] = [\n",
    "            -100\n",
    "        ] * question_len + full[\"labels\"][\n",
    "            question_len:\n",
    "        ]  \n",
    "        return full\n",
    "\n",
    "    tokenized_train_dataset = train_dataset.map(generate_prompt, remove_columns=['input','output'])\n",
    "    tokenized_val_dataset = eval_dataset.map(generate_prompt, remove_columns=['input','output'])\n",
    "\n",
    "\n",
    "    model.train()  # put model back into training mode\n",
    "\n",
    "    # model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    # config = IA3Config(\n",
    "    #         peft_type=\"IA3\",\n",
    "    #         task_type=\"CAUSAL_LM\",\n",
    "    #         )\n",
    "\n",
    "    # Apply LoRA to the model\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    output_dir = \"/drive/MyDrive/my_model_lora\"\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "            per_device_train_batch_size=3,\n",
    "            per_device_eval_batch_size=3,\n",
    "            gradient_accumulation_steps=1,\n",
    "            warmup_ratio=0.05,\n",
    "            num_train_epochs= 6,\n",
    "            learning_rate=2e-5,\n",
    "            lr_scheduler_type=\"cosine\",\n",
    "            fp16=False,\n",
    "            bf16= True,\n",
    "            optim=\"adamw_torch\",\n",
    "            eval_strategy=\"steps\", \n",
    "            save_strategy=\"no\",\n",
    "            eval_steps=0.2,\n",
    "            output_dir=output_dir,\n",
    "            load_best_model_at_end=False,\n",
    "            group_by_length=True, \n",
    "            report_to=\"none\", \n",
    "            run_name=None, \n",
    "            gradient_checkpointing=True,\n",
    "            dataloader_drop_last=True,\n",
    "            dataloader_pin_memory=True,\n",
    "            disable_tqdm = False,\n",
    "            dataloader_num_workers=4,\n",
    "        )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_val_dataset,\n",
    "        args=training_args,\n",
    "        data_collator=DataCollatorForSeq2Seq(\n",
    "            tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False\n",
    "\n",
    "    if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "        print(\"compiling the model\")\n",
    "        model = torch.compile(model)\n",
    "    # for param in model.parameters():\n",
    "    #     param.requires_grad = True\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    model.save_pretrained(output_dir)\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6756d0c4",
   "metadata": {},
   "source": [
    "# Inference Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23592832",
   "metadata": {},
   "source": [
    "## For RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "from peft import PeftModel,PeftConfig\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "device = \"cuda\"\n",
    "model_name_or_path = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"auto\",quantization_config={\"load_in_4bit\": True, \"bnb_4bit_compute_dtype\": torch.bfloat16})\n",
    "# model = get_peft_model(model, peft_config)\n",
    "# model.print_trainable_parameters()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.pad_token_id = 0 \n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "ADAPTER_PATH = \"my_model_qlora\"\n",
    "# model = AutoPeftModelForCausalLM.from_pretrained(ADAPTER_PATH,device_map=\"auto\",quantization_config={\"load_in_4bit\": True, \"bnb_4bit_compute_dtype\": torch.bfloat16})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,device_map=device,torch_dtype=torch.bfloat16)\n",
    "\n",
    "print(model.state_dict().keys())\n",
    "class Prompter:\n",
    "    PROMPT_TEMPLATE = \"\"\"You are an expert Solidity auditor specializing in smart contract security. Your task is to analyze Solidity smart contracts for vulnerabilities.\n",
    "\n",
    "@@ Instruction\n",
    "{instruction}\n",
    "\n",
    "@@ Response\n",
    "\"\"\"\n",
    "    @staticmethod\n",
    "    def generate_prompt(instruction: str) -> str:\n",
    "        return Prompter.PROMPT_TEMPLATE.format(instruction=instruction)\n",
    "\n",
    "def generate_benchmark_prompt(text: str) -> str:\n",
    "    BENCHMARK_PROMPT = \"\"\"Given the smart contract below, identify all potential security risks:\n",
    "    {problem}\"\"\"\n",
    "    formatted_text = BENCHMARK_PROMPT.format(problem=text)\n",
    "    return Prompter.generate_prompt(instruction=formatted_text)\n",
    "\n",
    "benchmark = json.load(open('benchmark_SB_CURATED.json', 'r'))\n",
    "\n",
    "model.to(\"cuda\")\n",
    "for k in range(len(benchmark)):\n",
    "    inputs = tokenizer(generate_benchmark_prompt(benchmark[k]['Code']), truncation=True,\n",
    "                    max_length=8196,\n",
    "                    padding=False,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "    eos_id = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs['input_ids'].cuda(),\n",
    "        attention_mask=inputs['attention_mask'].cuda(),\n",
    "        max_new_tokens= 500,\n",
    "        num_beams=10,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=eos_id,\n",
    "    )\n",
    "\n",
    "    all_output = []\n",
    "    for generated_id in generated_ids:\n",
    "        text = tokenizer.decode(generated_id[len(inputs[0]):], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "        all_output.append(text)\n",
    "    benchmark[k]['output'] = all_output\n",
    "\n",
    "# with open(f'codellama_base_smSBCURATED.json', \"w\") as f:\n",
    "#     json.dump(benchmark, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4b819",
   "metadata": {},
   "source": [
    "## For RQ2 and RQ3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d96fde9",
   "metadata": {},
   "source": [
    "### ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78cb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "from peft import PeftModel,PeftConfig\n",
    "from datetime import datetime\n",
    "import re\n",
    "# from humaneval_patch_validate import validate_humaneval\n",
    "# from quixbugs_patch_validate import validate_quixbugs\n",
    "# from  defects4j_patch_validate import validate_defects4j\n",
    "# from mbjp_apr_patch_validate import validate_mbjp_apr\n",
    "# from result_look import cal_result\n",
    "\n",
    "BENCHMARK_PROMPT = \"\"\"Write a solution to the following coding problem:\n",
    "The input is buggy code, which bug lines start from '// buggy lines start' and end at '// buggy lines end'. Please fix the follwing code.\n",
    "{problem}\"\"\"\n",
    "\n",
    "def create_model_and_tokenizer(model_name_or_path, model_type, load_in_4bit=True):\n",
    "    \"\"\"Create model and tokenizer.\"\"\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name_or_path,\n",
    "        torch_dtype=torch.float16,\n",
    "        load_in_4bit=load_in_4bit,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    # model = prepare_model_for_kbit_training(model)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name_or_path\n",
    "    )\n",
    "    if model_type == 'deepseek-coder-6.7b-base':\n",
    "        tokenizer.pad_token_id = 32018 #\"<pad>\"\n",
    "    else:\n",
    "        tokenizer.pad_token_id = 0 # unk. we want this to be different from the eos token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    print(model_type + f' pad token id is {tokenizer.pad_token_id}')\n",
    "    return model, tokenizer\n",
    "\n",
    "device = \"cuda\"\n",
    "model_name_or_path = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "tokenizer_name_or_path = \"codellama/CodeLlama-7b-hf\"\n",
    "\n",
    "# creating model\n",
    "# peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"auto\",quantization_config={\"load_in_4bit\": True, \"bnb_4bit_compute_dtype\": torch.float16})\n",
    "# model = get_peft_model(model, peft_config)\n",
    "# model.print_trainable_parameters()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.pad_token_id = 0 # unk. we want this to be different from the eos token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "ADAPTER_PATH = \"my_model_qlora\"\n",
    "# model = AutoPeftModelForCausalLM.from_pretrained(ADAPTER_PATH,device_map=\"auto\",quantization_config={\"load_in_4bit\": True, \"bnb_4bit_compute_dtype\": torch.bfloat16})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,device_map=device,torch_dtype=torch.bfloat16)\n",
    "\n",
    "print(model.state_dict().keys())\n",
    "class Prompter:\n",
    "    PROMPT_TEMPLATE = \"\"\"You are an expert Solidity auditor specializing in smart contract security. Your task is to analyze Solidity smart contracts for vulnerabilities.\n",
    "\n",
    "{instruction}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt(instruction: str) -> str:\n",
    "        return Prompter.PROMPT_TEMPLATE.format(instruction=instruction)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_response(output: str) -> str:\n",
    "        RESPONSE_SPLIT = \"@@ Response\\n\"\n",
    "        return output.split(RESPONSE_SPLIT)[1].strip() if RESPONSE_SPLIT in output else \"\"\n",
    "\n",
    "def generate_benchmark_prompt(text: str) -> str:\n",
    "    BENCHMARK_PROMPT = \"\"\"\n",
    "    {ICLs}\n",
    "\n",
    "    ```solidity\n",
    "    {problem}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    ICL = \"\"\"\n",
    "    ## Reentrancy\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract ReentrancyExample {\n",
    "        mapping(address => uint) public balances;\n",
    "\n",
    "        function deposit() public payable {\n",
    "            balances[msg.sender] += msg.value;\n",
    "        }\n",
    "\n",
    "        function withdraw(uint _amount) public {\n",
    "            require(balances[msg.sender] >= _amount, \"Insufficient balance\");\n",
    "            msg.sender.call.value(_amount)(\"\");\n",
    "            balances[msg.sender] -= _amount;\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Reentrancy]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    msg.sender.call.value(_amount)(\"\");\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    The balance is updated after the transfer, allowing potential reentrancy attacks.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract ReentrancyAttack {\n",
    "        mapping(address => uint256) public userBalances;\n",
    "\n",
    "        function depositFunds() public payable {\n",
    "            userBalances[msg.sender] += msg.value;\n",
    "        }\n",
    "\n",
    "        function withdrawFunds(uint256 _amount) public {\n",
    "            require(userBalances[msg.sender] >= _amount, \"Insufficient funds\");\n",
    "            msg.sender.call.value(_amount)(\"\");\n",
    "            userBalances[msg.sender] -= _amount;\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Reentrancy]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    msg.sender.call.value(_amount)(\"\");\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    The transfer happens before updating the balance, allowing reentrant functions to exploit.\n",
    "\n",
    "    ## Time Manipulation\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract TimeManipulationExample {\n",
    "        uint public deadline = now + 1 days;\n",
    "\n",
    "        function extendDeadline(uint _extraTime) public {\n",
    "            if (now < deadline) {\n",
    "                deadline += _extraTime;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Time Manipulation]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    deadline += _extraTime;\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    Miners can manipulate the timestamp to extend the deadline arbitrarily.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract TimeBoost {\n",
    "        uint public saleEndTime = now + 5 days;\n",
    "\n",
    "        function extendSale(uint _days) public {\n",
    "            if (now < saleEndTime) {\n",
    "                saleEndTime += _days * 1 days;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Time Manipulation]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    saleEndTime += _days * 1 days;\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    Use of now allows arbitrary extension due to miner-controlled timestamps.\n",
    "\n",
    "    ## Timestamp Dependence\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract TimestampGame {\n",
    "        uint public result;\n",
    "\n",
    "        function play() public {\n",
    "            if (now % 2 == 0) {\n",
    "                result = 1;\n",
    "            } else {\n",
    "                result = 0;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Timestamp Dependence]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    if (now % 2 == 0) {\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    Decisions based on timestamps can be influenced by miners for predictable outcomes.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract PredictableOutcome {\n",
    "        uint public outcome;\n",
    "\n",
    "        function determineOutcome() public {\n",
    "            if (now % 5 == 0) {\n",
    "                outcome = 100;\n",
    "            } else {\n",
    "                outcome = 50;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Timestamp Dependence]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    if (now % 5 == 0) {\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    Miner-controlled timestamps create predictable outcomes, reducing randomness.\n",
    "\n",
    "    ## Authorization\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract AuthorizationProblem {\n",
    "        address public owner;\n",
    "\n",
    "        function changeOwner(address _newOwner) public {\n",
    "            owner = _newOwner;\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Authorization]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    owner = _newOwner;\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    No access control exists, allowing any user to change the contract owner.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract AdminControl {\n",
    "        address public admin;\n",
    "\n",
    "        function setAdmin(address _newAdmin) public {\n",
    "            admin = _newAdmin;\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Authorization]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    admin = _newAdmin;\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    Lack of restrictions allows anyone to become the admin, opening the contract to misuse.\n",
    "\n",
    "    ## Unhandled Exception\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract UncheckedSend {\n",
    "        function sendPayment(address recipient, uint amount) public {\n",
    "            recipient.send(amount);\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Unhandled Exception]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    recipient.send(amount);\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    The send method fails silently, potentially leading to lost ether without corrective action.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract MissingRevert {\n",
    "        function executeTransfer(address recipient, uint amount) public {\n",
    "            recipient.send(amount);\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Unhandled Exception]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    recipient.send(amount);\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    Usage of send without checking for success means errors go unnoticed, risking ether loss.\n",
    "\n",
    "    ## Denial of Service\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract DOSWithRevert {\n",
    "        mapping(address => uint) public balances;\n",
    "        address[] public users;\n",
    "\n",
    "        function deposit() public payable {\n",
    "            balances[msg.sender] += msg.value;\n",
    "            users.push(msg.sender);\n",
    "        }\n",
    "\n",
    "        function withdraw() public {\n",
    "            require(balances[msg.sender] > 0, \"Insufficient balance\");\n",
    "            for (uint i = 0; i < users.length; i++) {\n",
    "                require(users[i] != msg.sender, \"Cannot process withdrawal\");\n",
    "            }\n",
    "            uint amount = balances[msg.sender];\n",
    "            balances[msg.sender] = 0;\n",
    "            msg.sender.transfer(amount);\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Denial of Service]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    require(users[i] != msg.sender, \"Cannot process withdrawal\");\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    The loop calling `require` on each user can cause a revert if many users exist, blocking legitimate withdrawals.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract UnboundedGasConsumption {\n",
    "        mapping(address => uint) public points;\n",
    "        address[] public players;\n",
    "\n",
    "        function addPlayer(address _player) public {\n",
    "            players.push(_player);\n",
    "        }\n",
    "\n",
    "        function rewardPoints() public {\n",
    "            for (uint i = 0; i < players.length; i++) {\n",
    "                points[players[i]] += 1;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Denial of Service]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    for (uint i = 0; i < players.length; i++) {\n",
    "    ```\n",
    "    [Explanation]:\n",
    "    As more players are added, the loop inside `rewardPoints` can consume too much gas, causing the function to fail.\n",
    "    \"\"\"\n",
    "    formatted_text = BENCHMARK_PROMPT.format(ICLs = ICL,problem=text)\n",
    "    return Prompter.generate_prompt(instruction=formatted_text)\n",
    "\n",
    "benchmark = json.load(open('benchmark_SB_CURATED.json', 'r'))\n",
    "\n",
    "model.to(\"cuda\")\n",
    "for k in range(len(benchmark)):\n",
    "    inputs = tokenizer(generate_benchmark_prompt(benchmark[k]['Code']), truncation=True,\n",
    "                    max_length=8196,\n",
    "                    padding=False,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "    eos_id = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs['input_ids'].cuda(),\n",
    "        attention_mask=inputs['attention_mask'].cuda(),\n",
    "        max_new_tokens= 500,\n",
    "        num_beams=10,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=eos_id,\n",
    "    )\n",
    "\n",
    "    all_output = []\n",
    "    for generated_id in generated_ids:\n",
    "        text = tokenizer.decode(generated_id[len(inputs[0]):], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "        all_output.append(text)\n",
    "    benchmark[k]['output'] = all_output\n",
    "\n",
    "# with open(f'codellama_base_smSBCURATED.json', \"w\") as f:\n",
    "#     json.dump(benchmark, f, indent=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938981e1",
   "metadata": {},
   "source": [
    "### CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2df42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "from peft import PeftModel,PeftConfig\n",
    "from datetime import datetime\n",
    "import re\n",
    "# from humaneval_patch_validate import validate_humaneval\n",
    "# from quixbugs_patch_validate import validate_quixbugs\n",
    "# from  defects4j_patch_validate import validate_defects4j\n",
    "# from mbjp_apr_patch_validate import validate_mbjp_apr\n",
    "# from result_look import cal_result\n",
    "\n",
    "BENCHMARK_PROMPT = \"\"\"Write a solution to the following coding problem:\n",
    "The input is buggy code, which bug lines start from '// buggy lines start' and end at '// buggy lines end'. Please fix the follwing code.\n",
    "{problem}\"\"\"\n",
    "\n",
    "def create_model_and_tokenizer(model_name_or_path, model_type, load_in_4bit=True):\n",
    "    \"\"\"Create model and tokenizer.\"\"\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name_or_path,\n",
    "        torch_dtype=torch.float16,\n",
    "        load_in_4bit=load_in_4bit,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    # model = prepare_model_for_kbit_training(model)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name_or_path\n",
    "    )\n",
    "    if model_type == 'deepseek-coder-6.7b-base':\n",
    "        tokenizer.pad_token_id = 32018 #\"<pad>\"\n",
    "    else:\n",
    "        tokenizer.pad_token_id = 0 # unk. we want this to be different from the eos token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    print(model_type + f' pad token id is {tokenizer.pad_token_id}')\n",
    "    return model, tokenizer\n",
    "\n",
    "device = \"cuda\"\n",
    "model_name_or_path = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "tokenizer_name_or_path = \"codellama/CodeLlama-7b-hf\"\n",
    "\n",
    "# creating model\n",
    "# peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"auto\",quantization_config={\"load_in_4bit\": True, \"bnb_4bit_compute_dtype\": torch.float16})\n",
    "# model = get_peft_model(model, peft_config)\n",
    "# model.print_trainable_parameters()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.pad_token_id = 0 # unk. we want this to be different from the eos token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "ADAPTER_PATH = \"my_model_qlora\"\n",
    "# model = AutoPeftModelForCausalLM.from_pretrained(ADAPTER_PATH,device_map=\"auto\",quantization_config={\"load_in_4bit\": True, \"bnb_4bit_compute_dtype\": torch.bfloat16})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,device_map=device,torch_dtype=torch.bfloat16)\n",
    "\n",
    "print(model.state_dict().keys())\n",
    "class Prompter:\n",
    "    PROMPT_TEMPLATE = \"\"\"You are an expert Solidity auditor specializing in smart contract security. Your task is to analyze Solidity smart contracts for vulnerabilities.\n",
    "\n",
    "{instruction}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prompt(instruction: str) -> str:\n",
    "        return Prompter.PROMPT_TEMPLATE.format(instruction=instruction)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_response(output: str) -> str:\n",
    "        RESPONSE_SPLIT = \"@@ Response\\n\"\n",
    "        return output.split(RESPONSE_SPLIT)[1].strip() if RESPONSE_SPLIT in output else \"\"\n",
    "\n",
    "def generate_benchmark_prompt(text: str) -> str:\n",
    "    BENCHMARK_PROMPT = \"\"\"\n",
    "    {ICLs}\n",
    "\n",
    "    ```solidity\n",
    "    {problem}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    ICL = \"\"\"\n",
    "    ## Reentrancy\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract ReentrancyExample {\n",
    "        mapping(address => uint) public balances;\n",
    "\n",
    "        function deposit() public payable {\n",
    "            balances[msg.sender] += msg.value;\n",
    "        }\n",
    "\n",
    "        function withdraw(uint _amount) public {\n",
    "            require(balances[msg.sender] >= _amount, \"Insufficient balance\");\n",
    "            msg.sender.call.value(_amount)(\"\");\n",
    "            balances[msg.sender] -= _amount;\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Reentrancy]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    msg.sender.call.value(_amount)(\"\");\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. The `withdraw` function first checks if the sender has enough balance.\n",
    "    2. It then sends the specified `_amount` to `msg.sender` using `call`.\n",
    "    3. Since the balance reduction occurs after the call, an attacker can reenter the function before the balance is updated.\n",
    "    4. This allows repeated withdrawals, draining the contract.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract ReentrancyAttack {\n",
    "        mapping(address => uint256) public userBalances;\n",
    "\n",
    "        function depositFunds() public payable {\n",
    "            userBalances[msg.sender] += msg.value;\n",
    "        }\n",
    "\n",
    "        function withdrawFunds(uint256 _amount) public {\n",
    "            require(userBalances[msg.sender] >= _amount, \"Insufficient funds\");\n",
    "            msg.sender.call.value(_amount)(\"\");\n",
    "            userBalances[msg.sender] -= _amount;\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Reentrancy]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    msg.sender.call.value(_amount)(\"\");\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. The `withdrawFunds` function checks if the user has sufficient funds.\n",
    "    2. It sends the withdrawal amount using `call`.\n",
    "    3. Before updating `userBalances`, the vulnerable call enables repeated calls to `withdrawFunds` via reentrancy.\n",
    "    4. This could lead to an attacker draining funds beyond their balance.\n",
    "\n",
    "    ## Time Manipulation\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract TimeManipulationExample {\n",
    "        uint public deadline = now + 1 days;\n",
    "\n",
    "        function extendDeadline(uint _extraTime) public {\n",
    "            if (now < deadline) {\n",
    "                deadline += _extraTime;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Time Manipulation]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    deadline += _extraTime;\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. The contract uses `now` to set a deadline.\n",
    "    2. The `extendDeadline` function allows adding extra time if the current `now` is less than `deadline`.\n",
    "    3. Miners can adjust `now` values slightly, extending the deadline.\n",
    "    4. This capability leads to arbitrary and unauthorized deadline extensions.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract TimeBoost {\n",
    "        uint public saleEndTime = now + 5 days;\n",
    "\n",
    "        function extendSale(uint _days) public {\n",
    "            if (now < saleEndTime) {\n",
    "                saleEndTime += _days * 1 days;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Time Manipulation]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    saleEndTime += _days * 1 days;\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. The sale period is set to expire in 5 days using `now`.\n",
    "    2. The `extendSale` function permits adding days to `saleEndTime`.\n",
    "    3. Since miners have control over `now`, they may manipulate timing to their advantage.\n",
    "    4. This can result in extensions beyond intended limits.\n",
    "\n",
    "    ## Timestamp Dependence\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract TimestampGame {\n",
    "        uint public result;\n",
    "\n",
    "        function play() public {\n",
    "            if (now % 2 == 0) {\n",
    "                result = 1;\n",
    "            } else {\n",
    "                result = 0;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Timestamp Dependence]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    if (now % 2 == 0) {\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. The function uses `now` to determine the game's result.\n",
    "    2. Depending on whether `now` is even or odd, different outcomes are produced.\n",
    "    3. Miners can set timestamps within reasonable limits to influence the game’s outcome.\n",
    "    4. This behavior breaks randomness and can predictably alter results.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract PredictableOutcome {\n",
    "        uint public outcome;\n",
    "\n",
    "        function determineOutcome() public {\n",
    "            if (now % 5 == 0) {\n",
    "                outcome = 100;\n",
    "            } else {\n",
    "                outcome = 50;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Timestamp Dependence]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    if (now % 5 == 0) {\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. The contract uses the remainder from `now % 5` to set `outcome`.\n",
    "    2. An exact time-derived condition determines the result.\n",
    "    3. Miners can craft block timestamps fitting the criteria, achieving specific outcomes.\n",
    "    4. This reduces the unpredictability, harming randomness and fairness.\n",
    "\n",
    "    ## Authorization\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract AuthorizationProblem {\n",
    "        address public owner;\n",
    "\n",
    "        function changeOwner(address _newOwner) public {\n",
    "            owner = _newOwner;\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Authorization]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    owner = _newOwner;\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. The contract’s `owner` can be changed via `changeOwner`.\n",
    "    2. There are no checks on the caller of this function.\n",
    "    3. Any user can call `changeOwner` and overwrite the `owner` address.\n",
    "    4. This leads to complete loss of control over ownership.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract AdminControl {\n",
    "        address public admin;\n",
    "\n",
    "        function setAdmin(address _newAdmin) public {\n",
    "            admin = _newAdmin;\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Authorization]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    admin = _newAdmin;\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. `setAdmin` changes the `admin` address.\n",
    "    2. Without access restrictions, anyone can invoke this function.\n",
    "    3. Unauthorized calls can replace the admin, making the contract susceptible to misuse.\n",
    "    4. This lack of security results in a compromised administrative role.\n",
    "\n",
    "    ## Unhandled Exception\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract UncheckedSend {\n",
    "        function sendPayment(address recipient, uint amount) public {\n",
    "            recipient.send(amount);\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Unhandled Exception]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    recipient.send(amount);\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. The `sendPayment` function tries to send a specified amount.\n",
    "    2. The `send` method sends ether and returns a boolean based on success/failure.\n",
    "    3. Here, the return value isn't checked; thus, sending failures go unnoticed.\n",
    "    4. Missing failure handling can lead to undetected ether loss, impacting the sender.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract MissingRevert {\n",
    "        function executeTransfer(address recipient, uint amount) public {\n",
    "            recipient.send(amount);\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Unhandled Exception]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    recipient.send(amount);\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. `executeTransfer` calls the `send` method, transferring ether.\n",
    "    2. The call’s outcome is neglected as its result isn’t evaluated.\n",
    "    3. Without checking, failed sends might not trigger corrective actions.\n",
    "    4. This oversight can result in ether losses, leading to financial discrepancies.\n",
    "\n",
    "    ## Denial of Service\n",
    "\n",
    "    ### Example 1\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract DOSWithRevert {\n",
    "        mapping(address => uint) public balances;\n",
    "        address[] public users;\n",
    "\n",
    "        function deposit() public payable {\n",
    "            balances[msg.sender] += msg.value;\n",
    "            users.push(msg.sender);\n",
    "        }\n",
    "\n",
    "        function withdraw() public {\n",
    "            require(balances[msg.sender] > 0, \"Insufficient balance\");\n",
    "            for (uint i = 0; i < users.length; i++) {\n",
    "                require(users[i] != msg.sender, \"Cannot process withdrawal\");\n",
    "            }\n",
    "            uint amount = balances[msg.sender];\n",
    "            balances[msg.sender] = 0;\n",
    "            msg.sender.transfer(amount);\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Denial of Service]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    require(users[i] != msg.sender, \"Cannot process withdrawal\");\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. The `withdraw` function aims to prevent duplicate withdrawals by iterating over `users`.\n",
    "    2. It checks if the user already exists before allowing withdrawal.\n",
    "    3. As the number of users increases, the loop may run out of gas.\n",
    "    4. This excessive gas use can lead to a revert, blocking any withdrawals.\n",
    "    5. Consequently, legitimate users cannot withdraw if the user list gets too large.\n",
    "\n",
    "    ### Example 2\n",
    "\n",
    "    ```solidity\n",
    "    pragma solidity ^0.4.24;\n",
    "\n",
    "    contract UnboundedGasConsumption {\n",
    "        mapping(address => uint) public points;\n",
    "        address[] public players;\n",
    "\n",
    "        function addPlayer(address _player) public {\n",
    "            players.push(_player);\n",
    "        }\n",
    "\n",
    "        function rewardPoints() public {\n",
    "            for (uint i = 0; i < players.length; i++) {\n",
    "                points[players[i]] += 1;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    [Output]:\n",
    "    [Denial of Service]:\n",
    "    [Function/Line]:\n",
    "    ```solidity\n",
    "    for (uint i = 0; i < players.length; i++) {\n",
    "    ```\n",
    "    [Step-by-step Explanation]:\n",
    "    1. The `rewardPoints` function increments points for each player.\n",
    "    2. It uses a loop iterating over all `players`.\n",
    "    3. As the number of players grows, the loop consumes an increasing amount of gas.\n",
    "    4. Once the gas limit is reached, the function calls will fail.\n",
    "    5. This failure effectively creates a denial of service, as updates to points cannot occur.\n",
    "    \"\"\"\n",
    "    formatted_text = BENCHMARK_PROMPT.format(ICLs = ICL,problem=text)\n",
    "    return Prompter.generate_prompt(instruction=formatted_text)\n",
    "\n",
    "benchmark = json.load(open('benchmark_SB_CURATED.json', 'r'))\n",
    "\n",
    "model.to(\"cuda\")\n",
    "for k in range(len(benchmark)):\n",
    "    inputs = tokenizer(generate_benchmark_prompt(benchmark[k]['Code']), truncation=True,\n",
    "                    max_length=8196,\n",
    "                    padding=False,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "    eos_id = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs['input_ids'].cuda(),\n",
    "        attention_mask=inputs['attention_mask'].cuda(),\n",
    "        max_new_tokens= 500,\n",
    "        num_beams=10,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=eos_id,\n",
    "    )\n",
    "\n",
    "    all_output = []\n",
    "    for generated_id in generated_ids:\n",
    "        text = tokenizer.decode(generated_id[len(inputs[0]):], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "        all_output.append(text)\n",
    "    benchmark[k]['output'] = all_output\n",
    "\n",
    "# with open(f'codellama_base_smSBCURATED.json', \"w\") as f:\n",
    "#     json.dump(benchmark, f, indent=2)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
